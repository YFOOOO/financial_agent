# 🧪 实验日志

> 记录所有优化尝试和实验结果

## 实验记录格式

每个实验使用以下模板：

---

### 实验 #001: [实验名称]

**日期**: 2025-12-14  
**目标**: [明确的优化目标]  
**假设**: [你认为会带来改进的原因]

#### 实验设计

**变量**:
- 自变量: [你改变的内容]
- 因变量: [你观察的指标]
- 对照组: v1.1.0 基准数据

**方法**:
1. [步骤1]
2. [步骤2]
3. [步骤3]

#### 结果

**性能数据**:
```json
{
  "llm_response_avg": 2.8,  // 原 3.5s
  "avg_total_tokens": 1800,  // 原 2500
  "improvement": "响应时间 -20%, Token -28%"
}
```

**质量评估**:
- 格式正确率: 95% (持平)
- 内容完整率: 90% (提升 2%)
- 用户反馈: [主观评价]

#### 结论

✅ **成功** / ⚠️ **部分成功** / ❌ **失败**

**分析**:
[解释为什么成功/失败，学到了什么]

**决策**:
- [ ] 合并到主分支
- [ ] 继续优化
- [ ] 放弃方案

**相关文件**:
- Notebook: `optimize_llm_prompts.ipynb`
- 基准数据: `benchmarks/v1.2.0_alpha_1.json`
- 代码提交: `commit abc123`

---

## 实验索引

| # | 日期 | 名称 | 目标 | 状态 | 结果 |
|---|------|------|------|------|------|
| 001 | 2025-12-14 | Prompt 精简优化 | 减少 Token 30% | ✅ | -28% Token, -20% 延迟 |
| 002 | 2025-12-15 | 数据缓存机制 | 提升获取速度 | 🔄 | 进行中 |
| 003 | 2025-12-16 | 指标向量化计算 | 提升计算效率 | 📝 | 待开始 |

---

## 实验详情

### 实验 #001: Prompt 精简优化

**日期**: 2025-12-14  
**目标**: 在不降低输出质量的前提下，减少 LLM Token 使用量 30%

**假设**: 当前 Prompt 包含过多冗余描述，精简后可以保持质量并降低成本

#### 实验设计

**变量**:
- 自变量: Prompt 长度和结构
  - 原版: 1200 tokens (系统 Prompt + 工具说明)
  - 优化版: 800 tokens (精简描述，保留核心指令)
- 因变量: Token 使用量、响应时间、输出质量
- 对照组: v1.1.0 基准数据

**方法**:
1. 分析当前 Prompt 的冗余部分
2. 保留核心指令，精简工具描述
3. 使用相同测试用例运行 10 次
4. 对比性能和质量数据

#### 结果

**性能数据**:
```json
{
  "llm_response_avg": 2.8,    // 原 3.5s (-20%)
  "avg_total_tokens": 1800,    // 原 2500 (-28%)
  "avg_prompt_tokens": 850,    // 原 1200 (-29%)
  "avg_completion_tokens": 950 // 原 1300 (-27%)
}
```

**质量评估**:
- 格式正确率: 95% (原 95%, 持平 ✅)
- 内容完整率: 90% (原 88%, +2% ✅)
- 趋势分析覆盖: 100% (原 100%, 持平 ✅)
- 指标分析覆盖: 95% (原 92%, +3% ✅)
- 建议提供率: 90% (原 85%, +5% ✅)

**成本对比**:
- 单次查询: ¥0.0025 (原 ¥0.0035, -28.6%)
- 1000次查询: ¥2.50 (原 ¥3.50, 节省 ¥1.00)

#### 结论

✅ **成功**

**分析**:
1. Prompt 精简后，Token 使用量降低 28%，超过预期目标
2. 响应时间缩短 20%，用户体验提升
3. 质量不仅没有下降，部分指标还有提升
4. 成本大幅降低，适合大规模应用

**关键发现**:
- 工具描述不需要过于详细，LLM 能理解简洁指令
- 移除了 Few-shot 示例中的冗余注释
- 使用更结构化的工具列表格式

**决策**:
- [x] 合并到主分支
- [ ] 继续优化
- [ ] 放弃方案

**相关文件**:
- Notebook: `optimize_llm_prompts.ipynb` (Cell 5-8)
- 基准数据: `benchmarks/v1.2.0_alpha_1.json`
- 代码提交: 待提交

---

### 实验 #002: 数据缓存机制

**日期**: 2025-12-15  
**目标**: 实现本地缓存，避免重复调用 AKShare API

**假设**: 同一股票的历史数据短期内不会变化，可以缓存 1 小时

#### 实验设计

**变量**:
- 自变量: 是否启用缓存
- 因变量: 数据获取时间、API 调用次数
- 对照组: v1.1.0 无缓存版本

**方法**:
1. 实现基于 `diskcache` 的缓存层
2. 设置 TTL=3600s (1小时)
3. 测试连续查询同一股票的性能

#### 结果

🔄 **进行中**

---

### 实验 #003: 指标向量化计算

**日期**: 2025-12-16  
**目标**: 使用 NumPy 向量化操作替代循环计算

**假设**: 向量化计算可以提升 50% 以上的计算速度

#### 实验设计

📝 **待开始**

**计划**:
1. 分析当前 `indicators.py` 中的瓶颈
2. 使用 `cProfile` 性能分析
3. 重写 MACD/RSI 计算逻辑
4. 基准对比

---

## 📚 实验最佳实践

### 实验前
- [ ] 明确优化目标（可量化）
- [ ] 建立假设（有理论支撑）
- [ ] 运行基准测试（有对照数据）
- [ ] 创建实验分支 (`git checkout -b exp/xxxx`)

### 实验中
- [ ] 记录所有尝试（包括失败的）
- [ ] 多次运行取平均值（至少 3 次）
- [ ] 同时关注性能和质量
- [ ] 保存中间结果（基准 JSON）

### 实验后
- [ ] 完整记录结果（数据 + 分析）
- [ ] 得出结论（成功/失败/部分成功）
- [ ] 做出决策（合并/继续/放弃）
- [ ] 更新文档（如果合并）

---

**维护者**: YFOOOO  
**最后更新**: 2025-12-14
