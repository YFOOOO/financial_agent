{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "70bd83a9",
   "metadata": {},
   "source": [
    "# ğŸ§ª è¯„ä¼°æ¡†æ¶ (Evaluation Framework)\n",
    "\n",
    "> ä¸ºä¸åŒç‰ˆæœ¬çš„ Agent å»ºç«‹å®Œæ•´çš„æ€§èƒ½ã€è´¨é‡å’Œæˆæœ¬åŸºå‡†\n",
    "\n",
    "**ç›®çš„**: ç”Ÿæˆç¬¦åˆ `comparison_report.ipynb` è¦æ±‚çš„åŸºå‡†æ•°æ®\n",
    "\n",
    "**è¯„ä¼°ç»´åº¦**:\n",
    "1. **æ€§èƒ½**: ç«¯åˆ°ç«¯è€—æ—¶ã€LLMå“åº”ã€æ•°æ®è·å–ã€æŒ‡æ ‡è®¡ç®—\n",
    "2. **è´¨é‡**: æ ¼å¼æ­£ç¡®ç‡ã€å†…å®¹å®Œæ•´ç‡ã€åˆ†æè¦ç´ è¦†ç›–ç‡\n",
    "3. **æˆæœ¬**: Tokenä½¿ç”¨é‡ã€APIè´¹ç”¨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e696a55a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Matplotlib ä¸­æ–‡å­—ä½“å·²é…ç½®: STHeiti\n",
      "âœ… æ¨¡å—å¯¼å…¥æˆåŠŸ\n",
      "ğŸ“… è¯„ä¼°æ—¶é—´: 2025-12-14 23:41:38\n"
     ]
    }
   ],
   "source": [
    "# 1. ç¯å¢ƒé…ç½®\n",
    "import sys\n",
    "import json\n",
    "import time\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from typing import Dict, List, Any\n",
    "import numpy as np\n",
    "\n",
    "# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "from agent_logic import run_agent\n",
    "from core.llm_client import get_response\n",
    "\n",
    "print(\"âœ… æ¨¡å—å¯¼å…¥æˆåŠŸ\")\n",
    "print(f\"ğŸ“… è¯„ä¼°æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c3c1a56",
   "metadata": {},
   "source": [
    "## ğŸ“‹ æµ‹è¯•ç”¨ä¾‹é›†"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "298d1076",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“ æµ‹è¯•ç”¨ä¾‹æ•°: 4\n",
      "  1. [relative_date] åˆ†æèŒ…å°æœ€è¿‘ä¸¤ä¸ªæœˆçš„èµ°åŠ¿\n",
      "  2. [year_to_date] çœ‹çœ‹å¹³å®‰é“¶è¡Œä»Šå¹´çš„è¡¨ç°\n",
      "  3. [multi_symbol] åˆ†æ 600519 å’Œ 000858 çš„ RSI\n",
      "  4. [etf_analysis] å¸®æˆ‘æŸ¥ä¸€ä¸‹æ²ªæ·±300ETFçš„æŠ€æœ¯æŒ‡æ ‡\n"
     ]
    }
   ],
   "source": [
    "# 2. å®šä¹‰æµ‹è¯•ç”¨ä¾‹\n",
    "TEST_CASES = [\n",
    "    {\n",
    "        \"query\": \"åˆ†æèŒ…å°æœ€è¿‘ä¸¤ä¸ªæœˆçš„èµ°åŠ¿\",\n",
    "        \"type\": \"relative_date\",\n",
    "        \"expected_elements\": [\"è¶‹åŠ¿\", \"MA\", \"MACD\", \"å›¾è¡¨\"]\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"çœ‹çœ‹å¹³å®‰é“¶è¡Œä»Šå¹´çš„è¡¨ç°\",\n",
    "        \"type\": \"year_to_date\",\n",
    "        \"expected_elements\": [\"å¹´åˆ\", \"æ¶¨è·Œ\", \"æŒ‡æ ‡\"]\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"åˆ†æ 600519 å’Œ 000858 çš„ RSI\",\n",
    "        \"type\": \"multi_symbol\",\n",
    "        \"expected_elements\": [\"RSI\", \"å¯¹æ¯”\"]\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"å¸®æˆ‘æŸ¥ä¸€ä¸‹æ²ªæ·±300ETFçš„æŠ€æœ¯æŒ‡æ ‡\",\n",
    "        \"type\": \"etf_analysis\",\n",
    "        \"expected_elements\": [\"ETF\", \"MACD\", \"RSI\"]\n",
    "    },\n",
    "]\n",
    "\n",
    "print(f\"ğŸ“ æµ‹è¯•ç”¨ä¾‹æ•°: {len(TEST_CASES)}\")\n",
    "for i, case in enumerate(TEST_CASES, 1):\n",
    "    print(f\"  {i}. [{case['type']}] {case['query']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f6a96b8",
   "metadata": {},
   "source": [
    "## ğŸ¯ è´¨é‡è¯„ä¼°å‡½æ•°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c7d5a3a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ§ª è´¨é‡è¯„ä¼°æµ‹è¯•:\n",
      "{'format_correct': 1.0, 'content_complete': 1.0, 'has_trend_analysis': 1.0, 'has_indicator_analysis': 1.0, 'has_chart': 1.0}\n"
     ]
    }
   ],
   "source": [
    "# 3. è´¨é‡è¯„ä¼°é€»è¾‘\n",
    "def evaluate_quality(result: Dict[str, Any], expected_elements: List[str]) -> Dict[str, float]:\n",
    "    \"\"\"\n",
    "    è¯„ä¼° Agent è¾“å‡ºçš„è´¨é‡\n",
    "    \n",
    "    Returns:\n",
    "        - format_correct: æ ¼å¼æ˜¯å¦æ­£ç¡®ï¼ˆæœ‰final_answerï¼‰\n",
    "        - content_complete: å†…å®¹å®Œæ•´æ€§ï¼ˆåŒ…å«æœŸæœ›å…ƒç´ çš„æ¯”ä¾‹ï¼‰\n",
    "        - has_trend_analysis: æ˜¯å¦æœ‰è¶‹åŠ¿åˆ†æ\n",
    "        - has_indicator_analysis: æ˜¯å¦æœ‰æŒ‡æ ‡åˆ†æ\n",
    "        - has_chart: æ˜¯å¦ç”Ÿæˆå›¾è¡¨\n",
    "    \"\"\"\n",
    "    final_answer = result.get(\"final_answer\", \"\")\n",
    "    \n",
    "    # 1. æ ¼å¼æ­£ç¡®æ€§ï¼ˆæ˜¯å¦æˆåŠŸè¿”å›final_answerï¼‰\n",
    "    format_correct = 1.0 if result.get(\"success\") and final_answer else 0.0\n",
    "    \n",
    "    # 2. å†…å®¹å®Œæ•´æ€§ï¼ˆåŒ…å«æœŸæœ›å…ƒç´ çš„æ¯”ä¾‹ï¼‰\n",
    "    if final_answer:\n",
    "        matched_elements = sum(1 for elem in expected_elements if elem in final_answer)\n",
    "        content_complete = matched_elements / len(expected_elements) if expected_elements else 0.0\n",
    "    else:\n",
    "        content_complete = 0.0\n",
    "    \n",
    "    # 3. åˆ†æè¦ç´ æ£€æŸ¥\n",
    "    has_trend_analysis = 1.0 if any(word in final_answer for word in [\"ä¸Šæ¶¨\", \"ä¸‹è·Œ\", \"éœ‡è¡\", \"è¶‹åŠ¿\"]) else 0.0\n",
    "    has_indicator_analysis = 1.0 if any(word in final_answer for word in [\"MA\", \"MACD\", \"RSI\", \"é‡‘å‰\", \"æ­»å‰\"]) else 0.0\n",
    "    has_chart = 1.0 if \"chart_path\" in result and result[\"chart_path\"] else 0.0\n",
    "    \n",
    "    return {\n",
    "        \"format_correct\": format_correct,\n",
    "        \"content_complete\": content_complete,\n",
    "        \"has_trend_analysis\": has_trend_analysis,\n",
    "        \"has_indicator_analysis\": has_indicator_analysis,\n",
    "        \"has_chart\": has_chart,\n",
    "    }\n",
    "\n",
    "# æµ‹è¯•è¯„ä¼°å‡½æ•°\n",
    "mock_result = {\n",
    "    \"success\": True,\n",
    "    \"final_answer\": \"èŒ…å°è¿‘æœŸå‘ˆéœ‡è¡ä¸Šæ¶¨è¶‹åŠ¿ï¼ŒMA5ä¸Šç©¿MA20å½¢æˆé‡‘å‰ï¼ŒMACDæŸ±çŠ¶å›¾è½¬æ­£\",\n",
    "    \"chart_path\": \"outputs/test.png\"\n",
    "}\n",
    "print(\"\\nğŸ§ª è´¨é‡è¯„ä¼°æµ‹è¯•:\")\n",
    "print(evaluate_quality(mock_result, [\"è¶‹åŠ¿\", \"MA\", \"MACD\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b47fb7c",
   "metadata": {},
   "source": [
    "## ğŸ’° æˆæœ¬ä¼°ç®—å‡½æ•°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "71bd81df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ’° æˆæœ¬ä¼°ç®—æµ‹è¯•:\n",
      "  2500 tokens (gpt-4o-mini): Â¥0.0063\n",
      "  2500 tokens (qwen-max): Â¥0.3000\n"
     ]
    }
   ],
   "source": [
    "# 4. Token æˆæœ¬ä¼°ç®—\n",
    "def estimate_cost(total_tokens: int, model: str = \"gpt-4o-mini\") -> float:\n",
    "    \"\"\"\n",
    "    ä¼°ç®— API è°ƒç”¨æˆæœ¬ï¼ˆäººæ°‘å¸ï¼‰\n",
    "    \n",
    "    ä»·æ ¼å‚è€ƒï¼ˆ2024å¹´12æœˆï¼‰ï¼š\n",
    "    - gpt-4o-mini: $0.15/1M input + $0.60/1M output (çº¦ Â¥1/1M + Â¥4/1M)\n",
    "    - qwen-max: Â¥0.12/1K tokens\n",
    "    - glm-4: Â¥0.10/1K tokens\n",
    "    \"\"\"\n",
    "    pricing = {\n",
    "        \"gpt-4o-mini\": 2.5 / 1_000_000,  # å¹³å‡ Â¥2.5/1M tokens\n",
    "        \"gpt-4o\": 15 / 1_000_000,\n",
    "        \"qwen-max\": 0.12 / 1000,\n",
    "        \"glm-4\": 0.10 / 1000,\n",
    "        \"deepseek-chat\": 0.014 / 1000,\n",
    "    }\n",
    "    \n",
    "    # æå–æ¨¡å‹å‰ç¼€ï¼ˆå¦‚ qwen3-max -> qwen-maxï¼‰\n",
    "    model_key = None\n",
    "    for key in pricing:\n",
    "        if key in model.lower():\n",
    "            model_key = key\n",
    "            break\n",
    "    \n",
    "    if not model_key:\n",
    "        model_key = \"gpt-4o-mini\"  # é»˜è®¤\n",
    "    \n",
    "    return total_tokens * pricing[model_key]\n",
    "\n",
    "print(\"ğŸ’° æˆæœ¬ä¼°ç®—æµ‹è¯•:\")\n",
    "print(f\"  2500 tokens (gpt-4o-mini): Â¥{estimate_cost(2500, 'gpt-4o-mini'):.4f}\")\n",
    "print(f\"  2500 tokens (qwen-max): Â¥{estimate_cost(2500, 'qwen-max'):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dd93c0c",
   "metadata": {},
   "source": [
    "## ğŸš€ è¿è¡Œå®Œæ•´è¯„ä¼°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4321435f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… è¯„ä¼°å‡½æ•°å·²å®šä¹‰\n"
     ]
    }
   ],
   "source": [
    "# 5. è¿è¡Œå®Œæ•´è¯„ä¼°\n",
    "def run_evaluation(\n",
    "    version: str,\n",
    "    test_cases: List[Dict],\n",
    "    model: str = \"gpt-4o-mini\",\n",
    "    verbose: bool = True\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    å¯¹æŒ‡å®šç‰ˆæœ¬è¿›è¡Œå®Œæ•´è¯„ä¼°\n",
    "    \"\"\"\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"ğŸ§ª è¯„ä¼°ç‰ˆæœ¬: {version}\")\n",
    "    print(f\"ğŸ¤– æµ‹è¯•æ¨¡å‹: {model}\")\n",
    "    print(f\"{'='*60}\\n\")\n",
    "    \n",
    "    results = []\n",
    "    performance_metrics = []\n",
    "    quality_metrics = []\n",
    "    cost_metrics = []\n",
    "    \n",
    "    for i, case in enumerate(test_cases, 1):\n",
    "        print(f\"[{i}/{len(test_cases)}] æµ‹è¯•: {case['query']}\")\n",
    "        \n",
    "        try:\n",
    "            # è¿è¡Œ Agentï¼ˆå¸¦æ€§èƒ½ç›‘æ§ï¼‰\n",
    "            start_time = time.time()\n",
    "            result = run_agent(\n",
    "                case[\"query\"],\n",
    "                model=model,\n",
    "                verbose=False  # å…³é—­è¯¦ç»†è¾“å‡ºä»¥åŠ é€Ÿ\n",
    "            )\n",
    "            end_time = time.time()\n",
    "            \n",
    "            duration = end_time - start_time\n",
    "            \n",
    "            # æ€§èƒ½æŒ‡æ ‡\n",
    "            performance_metrics.append({\n",
    "                \"end_to_end_time\": duration,\n",
    "                \"llm_response_time\": result.get(\"llm_time\", duration * 0.6),  # ä¼°ç®—\n",
    "                \"data_fetching_time\": result.get(\"data_time\", duration * 0.3),  # ä¼°ç®—\n",
    "            })\n",
    "            \n",
    "            # è´¨é‡æŒ‡æ ‡\n",
    "            quality = evaluate_quality(result, case[\"expected_elements\"])\n",
    "            quality_metrics.append(quality)\n",
    "            \n",
    "            # æˆæœ¬æŒ‡æ ‡\n",
    "            total_tokens = result.get(\"total_tokens\", 2500)  # é»˜è®¤ä¼°ç®—å€¼\n",
    "            cost = estimate_cost(total_tokens, model)\n",
    "            cost_metrics.append({\n",
    "                \"total_tokens\": total_tokens,\n",
    "                \"cost_cny\": cost\n",
    "            })\n",
    "            \n",
    "            status = \"âœ…\" if result.get(\"success\") else \"âŒ\"\n",
    "            print(f\"  {status} è€—æ—¶: {duration:.2f}s | Token: {total_tokens} | æˆæœ¬: Â¥{cost:.4f}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"  âŒ å¤±è´¥: {str(e)}\")\n",
    "            # è®°å½•å¤±è´¥æ¡ˆä¾‹\n",
    "            performance_metrics.append({\"end_to_end_time\": 0, \"llm_response_time\": 0, \"data_fetching_time\": 0})\n",
    "            quality_metrics.append({k: 0.0 for k in [\"format_correct\", \"content_complete\", \"has_trend_analysis\", \"has_indicator_analysis\", \"has_chart\"]})\n",
    "            cost_metrics.append({\"total_tokens\": 0, \"cost_cny\": 0})\n",
    "    \n",
    "    # æ±‡æ€»ç»Ÿè®¡\n",
    "    benchmark_data = {\n",
    "        \"version\": version,\n",
    "        \"timestamp\": datetime.now().isoformat(),\n",
    "        \"model\": model,\n",
    "        \"test_cases_count\": len(test_cases),\n",
    "        \"performance\": {\n",
    "            \"end_to_end_avg_time\": np.mean([m[\"end_to_end_time\"] for m in performance_metrics]),\n",
    "            \"llm_avg_response_time\": np.mean([m[\"llm_response_time\"] for m in performance_metrics]),\n",
    "            \"data_fetching_avg_time\": np.mean([m[\"data_fetching_time\"] for m in performance_metrics]),\n",
    "        },\n",
    "        \"quality\": {\n",
    "            \"format_correct_rate\": np.mean([m[\"format_correct\"] for m in quality_metrics]),\n",
    "            \"content_complete_rate\": np.mean([m[\"content_complete\"] for m in quality_metrics]),\n",
    "            \"has_trend_analysis_rate\": np.mean([m[\"has_trend_analysis\"] for m in quality_metrics]),\n",
    "            \"has_indicator_analysis_rate\": np.mean([m[\"has_indicator_analysis\"] for m in quality_metrics]),\n",
    "            \"has_chart_rate\": np.mean([m[\"has_chart\"] for m in quality_metrics]),\n",
    "        },\n",
    "        \"cost\": {\n",
    "            \"avg_total_tokens\": int(np.mean([m[\"total_tokens\"] for m in cost_metrics])),\n",
    "            \"total_cost_cny\": np.sum([m[\"cost_cny\"] for m in cost_metrics]),\n",
    "            \"avg_cost_per_query_cny\": np.mean([m[\"cost_cny\"] for m in cost_metrics]),\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    return benchmark_data\n",
    "\n",
    "print(\"âœ… è¯„ä¼°å‡½æ•°å·²å®šä¹‰\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aadabaf7",
   "metadata": {},
   "source": [
    "## ğŸ“Š æ‰§è¡Œè¯„ä¼°å¹¶ä¿å­˜ç»“æœ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "65054042",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸  æ³¨æ„: æ­¤è¿‡ç¨‹å°†è°ƒç”¨çœŸå®çš„ LLM APIï¼Œå¯èƒ½éœ€è¦ 1-2 åˆ†é’Ÿ\n",
      "ç¡®è®¤ç»§ç»­è¯·è¿è¡Œæ­¤å•å…ƒæ ¼...\n",
      "\n",
      "\n",
      "============================================================\n",
      "ğŸ§ª è¯„ä¼°ç‰ˆæœ¬: v1.2.0\n",
      "ğŸ¤– æµ‹è¯•æ¨¡å‹: gpt-4o-mini\n",
      "============================================================\n",
      "\n",
      "[1/4] æµ‹è¯•: åˆ†æèŒ…å°æœ€è¿‘ä¸¤ä¸ªæœˆçš„èµ°åŠ¿\n",
      "  âœ… è€—æ—¶: 0.00s | Token: 2500 | æˆæœ¬: Â¥0.0063\n",
      "[2/4] æµ‹è¯•: çœ‹çœ‹å¹³å®‰é“¶è¡Œä»Šå¹´çš„è¡¨ç°\n",
      "  âœ… è€—æ—¶: 0.00s | Token: 2500 | æˆæœ¬: Â¥0.0063\n",
      "[3/4] æµ‹è¯•: åˆ†æ 600519 å’Œ 000858 çš„ RSI\n",
      "  âœ… è€—æ—¶: 0.00s | Token: 2500 | æˆæœ¬: Â¥0.0063\n",
      "[4/4] æµ‹è¯•: å¸®æˆ‘æŸ¥ä¸€ä¸‹æ²ªæ·±300ETFçš„æŠ€æœ¯æŒ‡æ ‡\n",
      "  âœ… è€—æ—¶: 0.00s | Token: 2500 | æˆæœ¬: Â¥0.0063\n",
      "\n",
      "============================================================\n",
      "ğŸ“Š è¯„ä¼°ç»“æœæ±‡æ€»\n",
      "============================================================\n",
      "\n",
      "âš¡ æ€§èƒ½:\n",
      "  ç«¯åˆ°ç«¯å¹³å‡æ—¶é—´: 0.00s\n",
      "  LLM å“åº”æ—¶é—´: 0.00s\n",
      "\n",
      "âœ… è´¨é‡:\n",
      "  æ ¼å¼æ­£ç¡®ç‡: 100.0%\n",
      "  å†…å®¹å®Œæ•´ç‡: 0.0%\n",
      "\n",
      "ğŸ’° æˆæœ¬:\n",
      "  å¹³å‡ Token: 2500\n",
      "  æ€»æˆæœ¬: Â¥0.0250\n"
     ]
    }
   ],
   "source": [
    "# 6. è¿è¡Œè¯„ä¼°ï¼ˆå½“å‰ç‰ˆæœ¬ v1.2.0ï¼‰\n",
    "VERSION = \"v1.2.0\"\n",
    "MODEL = \"gpt-4o-mini\"  # å¯ä¿®æ”¹ä¸ºå…¶ä»–æ¨¡å‹\n",
    "\n",
    "print(\"âš ï¸  æ³¨æ„: æ­¤è¿‡ç¨‹å°†è°ƒç”¨çœŸå®çš„ LLM APIï¼Œå¯èƒ½éœ€è¦ 1-2 åˆ†é’Ÿ\")\n",
    "print(\"ç¡®è®¤ç»§ç»­è¯·è¿è¡Œæ­¤å•å…ƒæ ¼...\\n\")\n",
    "\n",
    "benchmark_result = run_evaluation(\n",
    "    version=VERSION,\n",
    "    test_cases=TEST_CASES,\n",
    "    model=MODEL,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# æ‰“å°æ±‡æ€»\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ğŸ“Š è¯„ä¼°ç»“æœæ±‡æ€»\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nâš¡ æ€§èƒ½:\")\n",
    "print(f\"  ç«¯åˆ°ç«¯å¹³å‡æ—¶é—´: {benchmark_result['performance']['end_to_end_avg_time']:.2f}s\")\n",
    "print(f\"  LLM å“åº”æ—¶é—´: {benchmark_result['performance']['llm_avg_response_time']:.2f}s\")\n",
    "\n",
    "print(f\"\\nâœ… è´¨é‡:\")\n",
    "print(f\"  æ ¼å¼æ­£ç¡®ç‡: {benchmark_result['quality']['format_correct_rate']*100:.1f}%\")\n",
    "print(f\"  å†…å®¹å®Œæ•´ç‡: {benchmark_result['quality']['content_complete_rate']*100:.1f}%\")\n",
    "\n",
    "print(f\"\\nğŸ’° æˆæœ¬:\")\n",
    "print(f\"  å¹³å‡ Token: {benchmark_result['cost']['avg_total_tokens']}\")\n",
    "print(f\"  æ€»æˆæœ¬: Â¥{benchmark_result['cost']['total_cost_cny']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4bb75ba2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… åŸºå‡†æ•°æ®å·²ä¿å­˜: benchmarks/v1.2.0_baseline.json\n",
      "\n",
      "ğŸ“ ä¸‹ä¸€æ­¥:\n",
      "  1. è¿è¡Œä¼˜åŒ–å®éªŒï¼ˆoptimize_llm_prompts.ipynbï¼‰\n",
      "  2. ç”Ÿæˆæ–°ç‰ˆæœ¬çš„åŸºå‡†æ•°æ®ï¼ˆä¿®æ”¹ VERSION åé‡æ–°è¿è¡Œæ­¤ Notebookï¼‰\n",
      "  3. ä½¿ç”¨ comparison_report.ipynb å¯¹æ¯”å¤šç‰ˆæœ¬æ•°æ®\n"
     ]
    }
   ],
   "source": [
    "# 7. ä¿å­˜åŸºå‡†æ•°æ®\n",
    "output_path = f\"benchmarks/{VERSION}_baseline.json\"\n",
    "\n",
    "with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(benchmark_result, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(f\"âœ… åŸºå‡†æ•°æ®å·²ä¿å­˜: {output_path}\")\n",
    "print(\"\\nğŸ“ ä¸‹ä¸€æ­¥:\")\n",
    "print(\"  1. è¿è¡Œä¼˜åŒ–å®éªŒï¼ˆoptimize_llm_prompts.ipynbï¼‰\")\n",
    "print(\"  2. ç”Ÿæˆæ–°ç‰ˆæœ¬çš„åŸºå‡†æ•°æ®ï¼ˆä¿®æ”¹ VERSION åé‡æ–°è¿è¡Œæ­¤ Notebookï¼‰\")\n",
    "print(\"  3. ä½¿ç”¨ comparison_report.ipynb å¯¹æ¯”å¤šç‰ˆæœ¬æ•°æ®\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.5)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
