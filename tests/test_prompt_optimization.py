"""
Pytest æ ¼å¼çš„ Prompt ä¼˜åŒ–æµ‹è¯•

æµ‹è¯•ä¸åŒç‰ˆæœ¬çš„ Promptï¼ŒéªŒè¯ä¼˜åŒ–æ•ˆæœ

æµ‹è¯•ç›®çš„ï¼š
1. éªŒè¯ v1 ç²¾ç®€ç‰ˆï¼ˆToken æœ€å°‘ï¼‰çš„å®é™…å‡†ç¡®æ€§
2. éªŒè¯ v3 CoTç‰ˆï¼ˆç†è®ºä¸Šæ›´ç¨³å¥ï¼‰çš„å®é™…è¡¨ç°
3. è‡ªåŠ¨åŒ–æµ‹è¯•ç¡®ä¿ä¼˜åŒ–åè´¨é‡ä¸ä¸‹é™

è¿è¡Œæ–¹å¼ï¼š
    pytest tests/test_prompt_optimization.py -v
    pytest tests/test_prompt_optimization.py::test_v1_prompt_quality -v
"""

import sys
from pathlib import Path
import pytest
from datetime import datetime
import time

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ° path
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from agent_logic import run_agent


# ============================================================================
# Pytest Fixtures
# ============================================================================

@pytest.fixture
def test_query():
    """æµ‹è¯•æŸ¥è¯¢è¯­å¥"""
    return "åˆ†æèŒ…å°æœ€è¿‘ä¸¤ä¸ªæœˆçš„èµ°åŠ¿"


@pytest.fixture
def test_model():
    """æµ‹è¯•ä½¿ç”¨çš„æ¨¡å‹"""
    return "gpt-4o-mini"  # ä½¿ç”¨å¿«é€Ÿæ¨¡å‹è¿›è¡Œæµ‹è¯•


@pytest.fixture
def v1_prompt():
    """v1 ç²¾ç®€ç‰ˆ Prompt"""
    current_date = datetime.now().strftime("%Yå¹´%mæœˆ%dæ—¥")
    return f"""ä½ æ˜¯é‡åŒ–é‡‘èåˆ†æå¸ˆåŠ©æ‰‹ã€‚ä»Šå¤©æ˜¯ {current_date}ã€‚

**æ ¸å¿ƒèƒ½åŠ›**ï¼šè·å–Aè‚¡/ETFæ•°æ®ï¼Œè®¡ç®—æŠ€æœ¯æŒ‡æ ‡ï¼Œç”ŸæˆKçº¿å›¾è¡¨ã€‚

**å·¥å…·**ï¼š

1. **fetch_stock_data**(symbol, days=60) - è·å–Aè‚¡æ•°æ®
   - symbol: è‚¡ç¥¨ä»£ç ï¼ˆå¦‚"600519"ï¼‰
   - days: å¤©æ•°ï¼ˆ"æœ€è¿‘ä¸¤ä¸ªæœˆ"=60ï¼Œ"è¿‘ä¸€å‘¨"=7ï¼‰

2. **fetch_etf_data**(symbol, days=60) - è·å–ETFæ•°æ®
   - symbol: ETFä»£ç ï¼ˆå¦‚"510300"ï¼‰
   - days: åŒä¸Š

3. **analyze_and_plot**(data_id, chart_type="comprehensive") - ç”Ÿæˆå›¾è¡¨
   - data_id: å‰é¢å·¥å…·è¿”å›çš„ID
   - chart_type: "auto"/"basic"/"comprehensive"

**æ‰§è¡Œæµç¨‹**ï¼š
1. æå–è‚¡ç¥¨ä»£ç å’Œå¤©æ•°
2. è°ƒç”¨fetchå·¥å…·ï¼ˆä¼˜å…ˆç”¨dayså‚æ•°ï¼‰
3. **å¿…é¡»**è°ƒç”¨analyze_and_plotç”Ÿæˆå›¾è¡¨
4. åŸºäºå›¾è¡¨æä¾›ç®€çŸ­åˆ†æ

**å“åº”æ ¼å¼**ï¼ˆJSONï¼‰ï¼š
{{
  "thought": "åˆ†æç”¨æˆ·éœ€æ±‚",
  "action": "å·¥å…·å",
  "action_input": {{"å‚æ•°": "å€¼"}}
}}

å®Œæˆæ—¶è¾“å‡ºï¼š{{"final_answer": "åˆ†æç»“è®º"}}
"""


@pytest.fixture
def v3_prompt(v1_prompt):
    """v3 CoTå¼•å¯¼ç‰ˆ Prompt"""
    cot_guide = """
**æ€ç»´é“¾æ­¥éª¤**ï¼ˆå¿…é¡»åœ¨ thought ä¸­ä½“ç°ï¼‰ï¼š
1. æ„å›¾è¯†åˆ« â†’ 2. å‚æ•°æå– â†’ 3. å·¥å…·é€‰æ‹© â†’ 4. æ‰§è¡Œ

ç¤ºä¾‹thoughtæ ¼å¼: "æ„å›¾:åˆ†æèŒ…å°èµ°åŠ¿ | å‚æ•°:600519,60å¤© | å·¥å…·:fetch_stock_data"
"""
    return v1_prompt + cot_guide


# ============================================================================
# è¾…åŠ©å‡½æ•°
# ============================================================================

def run_with_custom_prompt(prompt, query, model="gpt-4o-mini", verbose=False):
    """ä½¿ç”¨è‡ªå®šä¹‰ Prompt è¿è¡Œ Agent"""
    import agent_logic
    
    # ä¸´æ—¶æ›¿æ¢ Prompt
    original_get_prompt = agent_logic._get_system_prompt
    agent_logic._get_system_prompt = lambda: prompt
    
    try:
        start = time.time()
        result = run_agent(query, model=model, verbose=verbose)
        duration = time.time() - start
        
        # è´¨é‡æ£€æŸ¥
        final_answer = result.get('final_answer', '')
        has_trend = any(word in final_answer for word in ["ä¸Šæ¶¨", "ä¸‹è·Œ", "éœ‡è¡", "è¶‹åŠ¿"])
        has_indicator = any(word in final_answer for word in ["MA", "MACD", "RSI", "é‡‘å‰", "æ­»å‰"])
        
        return {
            "success": result.get('success', False),
            "duration": duration,
            "tokens": result.get('total_tokens'),
            "has_chart": bool(result.get('chart_path')),
            "has_trend": has_trend,
            "has_indicator": has_indicator,
            "final_answer": final_answer
        }
    finally:
        # æ¢å¤åŸå§‹ Prompt
        agent_logic._get_system_prompt = original_get_prompt


# ============================================================================
# æµ‹è¯•ç”¨ä¾‹
# ============================================================================

@pytest.mark.slow
@pytest.mark.skip(reason="éœ€è¦ LLM APIï¼Œæ‰‹åŠ¨è¿è¡Œ: pytest tests/test_prompt_optimization.py -m slow")
def test_v1_prompt_quality(v1_prompt, test_query, test_model):
    """æµ‹è¯• v1 ç²¾ç®€ç‰ˆ Prompt çš„è´¨é‡"""
    result = run_with_custom_prompt(v1_prompt, test_query, test_model)
    
    # åŸºæœ¬æ–­è¨€
    assert result["success"], "v1 ç²¾ç®€ç‰ˆæ‰§è¡Œå¤±è´¥"
    assert result["has_chart"], "v1 ç²¾ç®€ç‰ˆæœªç”Ÿæˆå›¾è¡¨"
    assert result["has_trend"], "v1 ç²¾ç®€ç‰ˆç¼ºå°‘è¶‹åŠ¿åˆ†æ"
    assert result["has_indicator"], "v1 ç²¾ç®€ç‰ˆç¼ºå°‘æŒ‡æ ‡åˆ†æ"
    
    # æ€§èƒ½æ–­è¨€ï¼ˆå…è®¸è¾ƒå¤§èŒƒå›´ï¼‰
    assert result["duration"] < 60, f"v1 ç²¾ç®€ç‰ˆæ‰§è¡Œè¶…æ—¶: {result['duration']:.2f}s"
    
    print(f"\nâœ… v1 ç²¾ç®€ç‰ˆæµ‹è¯•é€šè¿‡:")
    print(f"  è€—æ—¶: {result['duration']:.2f}s")
    print(f"  Token: {result['tokens']}")


@pytest.mark.slow
@pytest.mark.skip(reason="éœ€è¦ LLM APIï¼Œæ‰‹åŠ¨è¿è¡Œ: pytest tests/test_prompt_optimization.py -m slow")
def test_v3_prompt_quality(v3_prompt, test_query, test_model):
    """æµ‹è¯• v3 CoTç‰ˆ Prompt çš„è´¨é‡"""
    result = run_with_custom_prompt(v3_prompt, test_query, test_model)
    
    # åŸºæœ¬æ–­è¨€
    assert result["success"], "v3 CoTç‰ˆæ‰§è¡Œå¤±è´¥"
    assert result["has_chart"], "v3 CoTç‰ˆæœªç”Ÿæˆå›¾è¡¨"
    assert result["has_trend"], "v3 CoTç‰ˆç¼ºå°‘è¶‹åŠ¿åˆ†æ"
    assert result["has_indicator"], "v3 CoTç‰ˆç¼ºå°‘æŒ‡æ ‡åˆ†æ"
    
    # æ€§èƒ½æ–­è¨€
    assert result["duration"] < 60, f"v3 CoTç‰ˆæ‰§è¡Œè¶…æ—¶: {result['duration']:.2f}s"
    
    print(f"\nâœ… v3 CoTç‰ˆæµ‹è¯•é€šè¿‡:")
    print(f"  è€—æ—¶: {result['duration']:.2f}s")
    print(f"  Token: {result['tokens']}")


@pytest.mark.parametrize("prompt_version,version_name", [
    ("v1_prompt", "v1 ç²¾ç®€ç‰ˆ"),
    ("v3_prompt", "v3 CoTç‰ˆ"),
])
@pytest.mark.slow
@pytest.mark.skip(reason="éœ€è¦ LLM APIï¼Œæ‰‹åŠ¨è¿è¡Œ: pytest tests/test_prompt_optimization.py -m slow")
def test_prompt_versions_comparison(prompt_version, version_name, test_query, test_model, request):
    """å‚æ•°åŒ–æµ‹è¯•ï¼šå¯¹æ¯”ä¸åŒç‰ˆæœ¬çš„ Prompt"""
    prompt = request.getfixturevalue(prompt_version)
    result = run_with_custom_prompt(prompt, test_query, test_model)
    
    # é€šç”¨è´¨é‡æ£€æŸ¥
    assert result["success"], f"{version_name} æ‰§è¡Œå¤±è´¥"
    assert result["has_chart"], f"{version_name} æœªç”Ÿæˆå›¾è¡¨"
    
    print(f"\nğŸ“Š {version_name}:")
    print(f"  æˆåŠŸ: {result['success']}")
    print(f"  è€—æ—¶: {result['duration']:.2f}s")
    print(f"  Token: {result['tokens']}")
    print(f"  å›¾è¡¨: {'âœ…' if result['has_chart'] else 'âŒ'}")
    print(f"  è¶‹åŠ¿åˆ†æ: {'âœ…' if result['has_trend'] else 'âŒ'}")
    print(f"  æŒ‡æ ‡åˆ†æ: {'âœ…' if result['has_indicator'] else 'âŒ'}")
    
    print("\nğŸ’¡ å†³ç­–å»ºè®®:")
    print("  - å¦‚æœä¸¤ä¸ªç‰ˆæœ¬è´¨é‡ç›¸å½“ï¼Œé€‰æ‹© Token æ›´å°‘çš„ v1")
    print("  - å¦‚æœ v3 æ˜æ˜¾æ›´å‡†ç¡®ï¼Œé€‰æ‹© v3")
    print("  - è®°å½•å®é™… Token æ•°ï¼Œæ›´æ–°å®éªŒæŠ¥å‘Š")
